{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.058844 | Val Loss: 0.016019\n",
      "  -> New best model saved (val_loss: 0.016019) to `agent/mlp_model.pth`\n",
      "Epoch 02 | Train Loss: 0.013029 | Val Loss: 0.013874\n",
      "  -> New best model saved (val_loss: 0.013874) to `agent/mlp_model.pth`\n",
      "Epoch 03 | Train Loss: 0.010421 | Val Loss: 0.010650\n",
      "  -> New best model saved (val_loss: 0.010650) to `agent/mlp_model.pth`\n",
      "Epoch 04 | Train Loss: 0.008500 | Val Loss: 0.007003\n",
      "  -> New best model saved (val_loss: 0.007003) to `agent/mlp_model.pth`\n",
      "Epoch 05 | Train Loss: 0.005982 | Val Loss: 0.004947\n",
      "  -> New best model saved (val_loss: 0.004947) to `agent/mlp_model.pth`\n",
      "Epoch 06 | Train Loss: 0.004772 | Val Loss: 0.007122\n",
      "Epoch 07 | Train Loss: 0.004081 | Val Loss: 0.003385\n",
      "  -> New best model saved (val_loss: 0.003385) to `agent/mlp_model.pth`\n",
      "Epoch 08 | Train Loss: 0.003747 | Val Loss: 0.003603\n",
      "Epoch 09 | Train Loss: 0.003443 | Val Loss: 0.005024\n",
      "Epoch 10 | Train Loss: 0.003418 | Val Loss: 0.006583\n",
      "Epoch 11 | Train Loss: 0.003054 | Val Loss: 0.003427\n",
      "Epoch 12 | Train Loss: 0.002989 | Val Loss: 0.002722\n",
      "  -> New best model saved (val_loss: 0.002722) to `agent/mlp_model.pth`\n",
      "Epoch 13 | Train Loss: 0.002449 | Val Loss: 0.002232\n",
      "  -> New best model saved (val_loss: 0.002232) to `agent/mlp_model.pth`\n",
      "Epoch 14 | Train Loss: 0.002825 | Val Loss: 0.002192\n",
      "  -> New best model saved (val_loss: 0.002192) to `agent/mlp_model.pth`\n",
      "Epoch 15 | Train Loss: 0.002663 | Val Loss: 0.002193\n",
      "Epoch 16 | Train Loss: 0.002263 | Val Loss: 0.002837\n",
      "Epoch 17 | Train Loss: 0.002060 | Val Loss: 0.001726\n",
      "  -> New best model saved (val_loss: 0.001726) to `agent/mlp_model.pth`\n",
      "Epoch 18 | Train Loss: 0.002000 | Val Loss: 0.003825\n",
      "Epoch 19 | Train Loss: 0.002014 | Val Loss: 0.002242\n",
      "Epoch 20 | Train Loss: 0.002103 | Val Loss: 0.001555\n",
      "  -> New best model saved (val_loss: 0.001555) to `agent/mlp_model.pth`\n",
      "Epoch 21 | Train Loss: 0.001889 | Val Loss: 0.001555\n",
      "Epoch 22 | Train Loss: 0.001498 | Val Loss: 0.001526\n",
      "  -> New best model saved (val_loss: 0.001526) to `agent/mlp_model.pth`\n",
      "Epoch 23 | Train Loss: 0.001607 | Val Loss: 0.001496\n",
      "  -> New best model saved (val_loss: 0.001496) to `agent/mlp_model.pth`\n",
      "Epoch 24 | Train Loss: 0.001488 | Val Loss: 0.001672\n",
      "Epoch 25 | Train Loss: 0.001552 | Val Loss: 0.002964\n",
      "Epoch 26 | Train Loss: 0.001420 | Val Loss: 0.001181\n",
      "  -> New best model saved (val_loss: 0.001181) to `agent/mlp_model.pth`\n",
      "Epoch 27 | Train Loss: 0.001528 | Val Loss: 0.001489\n",
      "Epoch 28 | Train Loss: 0.001254 | Val Loss: 0.004380\n",
      "Epoch 29 | Train Loss: 0.001294 | Val Loss: 0.001607\n",
      "Epoch 30 | Train Loss: 0.001410 | Val Loss: 0.001176\n",
      "  -> New best model saved (val_loss: 0.001176) to `agent/mlp_model.pth`\n",
      "Epoch 31 | Train Loss: 0.001257 | Val Loss: 0.000810\n",
      "  -> New best model saved (val_loss: 0.000810) to `agent/mlp_model.pth`\n",
      "Epoch 32 | Train Loss: 0.001162 | Val Loss: 0.001236\n",
      "Epoch 33 | Train Loss: 0.001468 | Val Loss: 0.001701\n",
      "Epoch 34 | Train Loss: 0.000996 | Val Loss: 0.000831\n",
      "Epoch 35 | Train Loss: 0.001080 | Val Loss: 0.000715\n",
      "  -> New best model saved (val_loss: 0.000715) to `agent/mlp_model.pth`\n",
      "Epoch 36 | Train Loss: 0.001140 | Val Loss: 0.000765\n",
      "Epoch 37 | Train Loss: 0.001039 | Val Loss: 0.001418\n",
      "Epoch 38 | Train Loss: 0.001029 | Val Loss: 0.002183\n",
      "Epoch 39 | Train Loss: 0.001147 | Val Loss: 0.000914\n",
      "Epoch 40 | Train Loss: 0.001107 | Val Loss: 0.000789\n",
      "Epoch 41 | Train Loss: 0.001337 | Val Loss: 0.000726\n",
      "Epoch 42 | Train Loss: 0.000983 | Val Loss: 0.001475\n",
      "Epoch 43 | Train Loss: 0.001148 | Val Loss: 0.001615\n",
      "Epoch 44 | Train Loss: 0.000856 | Val Loss: 0.000751\n",
      "Epoch 45 | Train Loss: 0.001037 | Val Loss: 0.000812\n",
      "Epoch 46 | Train Loss: 0.001033 | Val Loss: 0.001166\n",
      "Epoch 47 | Train Loss: 0.000978 | Val Loss: 0.000659\n",
      "  -> New best model saved (val_loss: 0.000659) to `agent/mlp_model.pth`\n",
      "Epoch 48 | Train Loss: 0.000934 | Val Loss: 0.001004\n",
      "Epoch 49 | Train Loss: 0.001156 | Val Loss: 0.001881\n",
      "Epoch 50 | Train Loss: 0.000909 | Val Loss: 0.000671\n",
      "Epoch 51 | Train Loss: 0.000878 | Val Loss: 0.000765\n",
      "Epoch 52 | Train Loss: 0.000903 | Val Loss: 0.000658\n",
      "  -> New best model saved (val_loss: 0.000658) to `agent/mlp_model.pth`\n",
      "Epoch 53 | Train Loss: 0.000767 | Val Loss: 0.000610\n",
      "  -> New best model saved (val_loss: 0.000610) to `agent/mlp_model.pth`\n",
      "Epoch 54 | Train Loss: 0.000894 | Val Loss: 0.001760\n",
      "Epoch 55 | Train Loss: 0.000995 | Val Loss: 0.003394\n",
      "Epoch 56 | Train Loss: 0.000953 | Val Loss: 0.000863\n",
      "Epoch 57 | Train Loss: 0.000913 | Val Loss: 0.000607\n",
      "  -> New best model saved (val_loss: 0.000607) to `agent/mlp_model.pth`\n",
      "Epoch 58 | Train Loss: 0.000820 | Val Loss: 0.000737\n",
      "Epoch 59 | Train Loss: 0.000803 | Val Loss: 0.000738\n",
      "Epoch 60 | Train Loss: 0.000829 | Val Loss: 0.000756\n",
      "Epoch 61 | Train Loss: 0.001186 | Val Loss: 0.000589\n",
      "  -> New best model saved (val_loss: 0.000589) to `agent/mlp_model.pth`\n",
      "Epoch 62 | Train Loss: 0.000781 | Val Loss: 0.000875\n",
      "Epoch 63 | Train Loss: 0.000861 | Val Loss: 0.000546\n",
      "  -> New best model saved (val_loss: 0.000546) to `agent/mlp_model.pth`\n",
      "Epoch 64 | Train Loss: 0.000829 | Val Loss: 0.000546\n",
      "  -> New best model saved (val_loss: 0.000546) to `agent/mlp_model.pth`\n",
      "Epoch 65 | Train Loss: 0.000699 | Val Loss: 0.000810\n",
      "Epoch 66 | Train Loss: 0.001027 | Val Loss: 0.002993\n",
      "Epoch 67 | Train Loss: 0.000705 | Val Loss: 0.000767\n",
      "Epoch 68 | Train Loss: 0.000802 | Val Loss: 0.002278\n",
      "Epoch 69 | Train Loss: 0.000917 | Val Loss: 0.000703\n",
      "Epoch 70 | Train Loss: 0.000785 | Val Loss: 0.000816\n",
      "Epoch 71 | Train Loss: 0.000758 | Val Loss: 0.000555\n",
      "Epoch 72 | Train Loss: 0.000729 | Val Loss: 0.000954\n",
      "Epoch 73 | Train Loss: 0.000860 | Val Loss: 0.000585\n",
      "Epoch 74 | Train Loss: 0.000815 | Val Loss: 0.001536\n",
      "Epoch 75 | Train Loss: 0.000736 | Val Loss: 0.001668\n",
      "Epoch 76 | Train Loss: 0.000869 | Val Loss: 0.002229\n",
      "Epoch 77 | Train Loss: 0.000737 | Val Loss: 0.000448\n",
      "  -> New best model saved (val_loss: 0.000448) to `agent/mlp_model.pth`\n",
      "Epoch 78 | Train Loss: 0.000925 | Val Loss: 0.001010\n",
      "Epoch 79 | Train Loss: 0.000692 | Val Loss: 0.000754\n",
      "Epoch 80 | Train Loss: 0.000661 | Val Loss: 0.001119\n",
      "Epoch 81 | Train Loss: 0.000758 | Val Loss: 0.000489\n",
      "Epoch 82 | Train Loss: 0.000746 | Val Loss: 0.000449\n",
      "Epoch 83 | Train Loss: 0.000697 | Val Loss: 0.000493\n",
      "Epoch 84 | Train Loss: 0.000589 | Val Loss: 0.000592\n",
      "Epoch 85 | Train Loss: 0.000738 | Val Loss: 0.000511\n",
      "Epoch 86 | Train Loss: 0.000701 | Val Loss: 0.000574\n",
      "Epoch 87 | Train Loss: 0.000723 | Val Loss: 0.000394\n",
      "  -> New best model saved (val_loss: 0.000394) to `agent/mlp_model.pth`\n",
      "Epoch 88 | Train Loss: 0.000597 | Val Loss: 0.000619\n",
      "Epoch 89 | Train Loss: 0.000698 | Val Loss: 0.000808\n",
      "Epoch 90 | Train Loss: 0.000614 | Val Loss: 0.000397\n",
      "Epoch 91 | Train Loss: 0.000679 | Val Loss: 0.000398\n",
      "Epoch 92 | Train Loss: 0.000713 | Val Loss: 0.000506\n",
      "Epoch 93 | Train Loss: 0.000651 | Val Loss: 0.000398\n",
      "Epoch 94 | Train Loss: 0.000703 | Val Loss: 0.000886\n",
      "Epoch 95 | Train Loss: 0.000804 | Val Loss: 0.000569\n",
      "Epoch 96 | Train Loss: 0.000562 | Val Loss: 0.000527\n",
      "Epoch 97 | Train Loss: 0.000711 | Val Loss: 0.000509\n",
      "Epoch 98 | Train Loss: 0.000564 | Val Loss: 0.000447\n",
      "Epoch 99 | Train Loss: 0.000571 | Val Loss: 0.000957\n",
      "Epoch 100 | Train Loss: 0.000565 | Val Loss: 0.000610\n",
      "Epoch 101 | Train Loss: 0.000588 | Val Loss: 0.000720\n",
      "Epoch 102 | Train Loss: 0.000598 | Val Loss: 0.000798\n",
      "Epoch 103 | Train Loss: 0.000578 | Val Loss: 0.000516\n",
      "Epoch 104 | Train Loss: 0.000603 | Val Loss: 0.000818\n",
      "Epoch 105 | Train Loss: 0.000696 | Val Loss: 0.000431\n",
      "Epoch 106 | Train Loss: 0.000591 | Val Loss: 0.000622\n",
      "Epoch 107 | Train Loss: 0.001029 | Val Loss: 0.000429\n",
      "Epoch 108 | Train Loss: 0.000487 | Val Loss: 0.000602\n",
      "Epoch 109 | Train Loss: 0.000535 | Val Loss: 0.000829\n",
      "Epoch 110 | Train Loss: 0.000579 | Val Loss: 0.000396\n",
      "Epoch 111 | Train Loss: 0.000573 | Val Loss: 0.000849\n",
      "Epoch 112 | Train Loss: 0.000507 | Val Loss: 0.001171\n",
      "Epoch 113 | Train Loss: 0.000833 | Val Loss: 0.000455\n",
      "Epoch 114 | Train Loss: 0.000517 | Val Loss: 0.002572\n",
      "Epoch 115 | Train Loss: 0.000548 | Val Loss: 0.000433\n",
      "Epoch 116 | Train Loss: 0.000495 | Val Loss: 0.000427\n",
      "Epoch 117 | Train Loss: 0.000514 | Val Loss: 0.000630\n",
      "Epoch 118 | Train Loss: 0.000656 | Val Loss: 0.000756\n",
      "Epoch 119 | Train Loss: 0.000595 | Val Loss: 0.002710\n",
      "Epoch 120 | Train Loss: 0.000569 | Val Loss: 0.000326\n",
      "  -> New best model saved (val_loss: 0.000326) to `agent/mlp_model.pth`\n",
      "Epoch 121 | Train Loss: 0.000748 | Val Loss: 0.000631\n",
      "Epoch 122 | Train Loss: 0.000449 | Val Loss: 0.000376\n",
      "Epoch 123 | Train Loss: 0.000463 | Val Loss: 0.000327\n",
      "Epoch 124 | Train Loss: 0.000578 | Val Loss: 0.000982\n",
      "Epoch 125 | Train Loss: 0.000589 | Val Loss: 0.000935\n",
      "Epoch 126 | Train Loss: 0.000472 | Val Loss: 0.000539\n",
      "Epoch 127 | Train Loss: 0.000558 | Val Loss: 0.000560\n",
      "Epoch 128 | Train Loss: 0.000477 | Val Loss: 0.000349\n",
      "Epoch 129 | Train Loss: 0.000502 | Val Loss: 0.000473\n",
      "Epoch 130 | Train Loss: 0.000471 | Val Loss: 0.000336\n",
      "Epoch 131 | Train Loss: 0.000649 | Val Loss: 0.000762\n",
      "Epoch 132 | Train Loss: 0.000481 | Val Loss: 0.000506\n",
      "Epoch 133 | Train Loss: 0.000492 | Val Loss: 0.000297\n",
      "  -> New best model saved (val_loss: 0.000297) to `agent/mlp_model.pth`\n",
      "Epoch 134 | Train Loss: 0.000484 | Val Loss: 0.000535\n",
      "Epoch 135 | Train Loss: 0.000540 | Val Loss: 0.000473\n",
      "Epoch 136 | Train Loss: 0.000550 | Val Loss: 0.000351\n",
      "Epoch 137 | Train Loss: 0.000439 | Val Loss: 0.000277\n",
      "  -> New best model saved (val_loss: 0.000277) to `agent/mlp_model.pth`\n",
      "Epoch 138 | Train Loss: 0.000448 | Val Loss: 0.000305\n",
      "Epoch 139 | Train Loss: 0.000678 | Val Loss: 0.000403\n",
      "Epoch 140 | Train Loss: 0.000482 | Val Loss: 0.000677\n",
      "Epoch 141 | Train Loss: 0.000487 | Val Loss: 0.000360\n",
      "Epoch 142 | Train Loss: 0.000440 | Val Loss: 0.000351\n",
      "Epoch 143 | Train Loss: 0.000418 | Val Loss: 0.000466\n",
      "Epoch 144 | Train Loss: 0.000525 | Val Loss: 0.000870\n",
      "Epoch 145 | Train Loss: 0.000507 | Val Loss: 0.000479\n",
      "Epoch 146 | Train Loss: 0.000432 | Val Loss: 0.003016\n",
      "Epoch 147 | Train Loss: 0.000508 | Val Loss: 0.000304\n",
      "Epoch 148 | Train Loss: 0.000402 | Val Loss: 0.000675\n",
      "Epoch 149 | Train Loss: 0.000453 | Val Loss: 0.000578\n",
      "Epoch 150 | Train Loss: 0.000479 | Val Loss: 0.000484\n",
      "Epoch 151 | Train Loss: 0.000450 | Val Loss: 0.001404\n",
      "Epoch 152 | Train Loss: 0.000470 | Val Loss: 0.000346\n",
      "Epoch 153 | Train Loss: 0.000462 | Val Loss: 0.000366\n",
      "Epoch 154 | Train Loss: 0.000586 | Val Loss: 0.000293\n",
      "Epoch 155 | Train Loss: 0.000501 | Val Loss: 0.000287\n",
      "Epoch 156 | Train Loss: 0.000466 | Val Loss: 0.000653\n",
      "Epoch 157 | Train Loss: 0.000465 | Val Loss: 0.000465\n",
      "Epoch 158 | Train Loss: 0.000402 | Val Loss: 0.000957\n",
      "Epoch 159 | Train Loss: 0.000420 | Val Loss: 0.000286\n",
      "Epoch 160 | Train Loss: 0.000527 | Val Loss: 0.001090\n",
      "Epoch 161 | Train Loss: 0.000465 | Val Loss: 0.000505\n",
      "Epoch 162 | Train Loss: 0.000455 | Val Loss: 0.000317\n",
      "Epoch 163 | Train Loss: 0.000387 | Val Loss: 0.000383\n",
      "Epoch 164 | Train Loss: 0.000563 | Val Loss: 0.000290\n",
      "Epoch 165 | Train Loss: 0.000344 | Val Loss: 0.001281\n",
      "Epoch 166 | Train Loss: 0.000484 | Val Loss: 0.000319\n",
      "Epoch 167 | Train Loss: 0.000580 | Val Loss: 0.000280\n",
      "Epoch 168 | Train Loss: 0.000330 | Val Loss: 0.000385\n",
      "Epoch 169 | Train Loss: 0.000430 | Val Loss: 0.000300\n",
      "Epoch 170 | Train Loss: 0.000437 | Val Loss: 0.000362\n",
      "Epoch 171 | Train Loss: 0.000486 | Val Loss: 0.000282\n",
      "Epoch 172 | Train Loss: 0.000432 | Val Loss: 0.000496\n",
      "Epoch 173 | Train Loss: 0.000489 | Val Loss: 0.000764\n",
      "Epoch 174 | Train Loss: 0.000469 | Val Loss: 0.001297\n",
      "Epoch 175 | Train Loss: 0.000369 | Val Loss: 0.000501\n",
      "Epoch 176 | Train Loss: 0.000374 | Val Loss: 0.000413\n",
      "Epoch 177 | Train Loss: 0.000467 | Val Loss: 0.001839\n",
      "Epoch 178 | Train Loss: 0.000447 | Val Loss: 0.000261\n",
      "  -> New best model saved (val_loss: 0.000261) to `agent/mlp_model.pth`\n",
      "Epoch 179 | Train Loss: 0.000369 | Val Loss: 0.000388\n",
      "Epoch 180 | Train Loss: 0.000374 | Val Loss: 0.000391\n",
      "Epoch 181 | Train Loss: 0.000348 | Val Loss: 0.000729\n",
      "Epoch 182 | Train Loss: 0.000432 | Val Loss: 0.000287\n",
      "Epoch 183 | Train Loss: 0.000413 | Val Loss: 0.000447\n",
      "Epoch 184 | Train Loss: 0.000400 | Val Loss: 0.000271\n",
      "Epoch 185 | Train Loss: 0.000516 | Val Loss: 0.000866\n",
      "Epoch 186 | Train Loss: 0.000365 | Val Loss: 0.000311\n",
      "Epoch 187 | Train Loss: 0.000332 | Val Loss: 0.000341\n",
      "Epoch 188 | Train Loss: 0.000448 | Val Loss: 0.000287\n",
      "Epoch 189 | Train Loss: 0.000357 | Val Loss: 0.001738\n",
      "Epoch 190 | Train Loss: 0.000470 | Val Loss: 0.000296\n",
      "Epoch 191 | Train Loss: 0.000404 | Val Loss: 0.000365\n",
      "Epoch 192 | Train Loss: 0.000394 | Val Loss: 0.000274\n",
      "Epoch 193 | Train Loss: 0.000370 | Val Loss: 0.001956\n",
      "Epoch 194 | Train Loss: 0.000362 | Val Loss: 0.000264\n",
      "Epoch 195 | Train Loss: 0.000484 | Val Loss: 0.000468\n",
      "Epoch 196 | Train Loss: 0.000344 | Val Loss: 0.000425\n",
      "Epoch 197 | Train Loss: 0.000422 | Val Loss: 0.001719\n",
      "Epoch 198 | Train Loss: 0.000426 | Val Loss: 0.000504\n",
      "Epoch 199 | Train Loss: 0.000393 | Val Loss: 0.000537\n",
      "Epoch 200 | Train Loss: 0.000390 | Val Loss: 0.000438\n",
      "Epoch 201 | Train Loss: 0.000421 | Val Loss: 0.000249\n",
      "  -> New best model saved (val_loss: 0.000249) to `agent/mlp_model.pth`\n",
      "Epoch 202 | Train Loss: 0.000332 | Val Loss: 0.000313\n",
      "Epoch 203 | Train Loss: 0.000355 | Val Loss: 0.000272\n",
      "Epoch 204 | Train Loss: 0.000557 | Val Loss: 0.000443\n",
      "Epoch 205 | Train Loss: 0.000418 | Val Loss: 0.000826\n",
      "Epoch 206 | Train Loss: 0.000416 | Val Loss: 0.000533\n",
      "Epoch 207 | Train Loss: 0.000365 | Val Loss: 0.000276\n",
      "Epoch 208 | Train Loss: 0.000309 | Val Loss: 0.000388\n",
      "Epoch 209 | Train Loss: 0.000395 | Val Loss: 0.000316\n",
      "Epoch 210 | Train Loss: 0.000324 | Val Loss: 0.000223\n",
      "  -> New best model saved (val_loss: 0.000223) to `agent/mlp_model.pth`\n",
      "Epoch 211 | Train Loss: 0.000430 | Val Loss: 0.000789\n",
      "Epoch 212 | Train Loss: 0.000312 | Val Loss: 0.000292\n",
      "Epoch 213 | Train Loss: 0.000379 | Val Loss: 0.000341\n",
      "Epoch 214 | Train Loss: 0.000421 | Val Loss: 0.000996\n",
      "Epoch 215 | Train Loss: 0.000671 | Val Loss: 0.000404\n",
      "Epoch 216 | Train Loss: 0.000334 | Val Loss: 0.000473\n",
      "Epoch 217 | Train Loss: 0.000316 | Val Loss: 0.000222\n",
      "  -> New best model saved (val_loss: 0.000222) to `agent/mlp_model.pth`\n",
      "Epoch 218 | Train Loss: 0.000328 | Val Loss: 0.000432\n",
      "Epoch 219 | Train Loss: 0.000330 | Val Loss: 0.000284\n",
      "Epoch 220 | Train Loss: 0.000354 | Val Loss: 0.000823\n",
      "Epoch 221 | Train Loss: 0.000352 | Val Loss: 0.000358\n",
      "Epoch 222 | Train Loss: 0.000483 | Val Loss: 0.000309\n",
      "Epoch 223 | Train Loss: 0.000364 | Val Loss: 0.001191\n",
      "Epoch 224 | Train Loss: 0.000314 | Val Loss: 0.000271\n",
      "Epoch 225 | Train Loss: 0.000377 | Val Loss: 0.000241\n",
      "Epoch 226 | Train Loss: 0.000311 | Val Loss: 0.000280\n",
      "Epoch 227 | Train Loss: 0.000362 | Val Loss: 0.000645\n",
      "Epoch 228 | Train Loss: 0.000343 | Val Loss: 0.000209\n",
      "  -> New best model saved (val_loss: 0.000209) to `agent/mlp_model.pth`\n",
      "Epoch 229 | Train Loss: 0.000394 | Val Loss: 0.000666\n",
      "Epoch 230 | Train Loss: 0.000432 | Val Loss: 0.001107\n",
      "Epoch 231 | Train Loss: 0.000395 | Val Loss: 0.000448\n",
      "Epoch 232 | Train Loss: 0.000556 | Val Loss: 0.000348\n",
      "Epoch 233 | Train Loss: 0.000307 | Val Loss: 0.000257\n",
      "Epoch 234 | Train Loss: 0.000311 | Val Loss: 0.000497\n",
      "Epoch 235 | Train Loss: 0.000400 | Val Loss: 0.000327\n",
      "Epoch 236 | Train Loss: 0.000335 | Val Loss: 0.000239\n",
      "Epoch 237 | Train Loss: 0.000334 | Val Loss: 0.000555\n",
      "Epoch 238 | Train Loss: 0.000443 | Val Loss: 0.000686\n",
      "Epoch 239 | Train Loss: 0.000302 | Val Loss: 0.000230\n",
      "Epoch 240 | Train Loss: 0.000325 | Val Loss: 0.000241\n",
      "Epoch 241 | Train Loss: 0.000371 | Val Loss: 0.000311\n",
      "Epoch 242 | Train Loss: 0.000339 | Val Loss: 0.000294\n",
      "Epoch 243 | Train Loss: 0.000341 | Val Loss: 0.000325\n",
      "Epoch 244 | Train Loss: 0.000472 | Val Loss: 0.002213\n",
      "Epoch 245 | Train Loss: 0.000380 | Val Loss: 0.000407\n",
      "Epoch 246 | Train Loss: 0.000334 | Val Loss: 0.000421\n",
      "Epoch 247 | Train Loss: 0.000320 | Val Loss: 0.000336\n",
      "Epoch 248 | Train Loss: 0.000336 | Val Loss: 0.000532\n",
      "Epoch 249 | Train Loss: 0.000379 | Val Loss: 0.000902\n",
      "Epoch 250 | Train Loss: 0.000312 | Val Loss: 0.000404\n",
      "Epoch 251 | Train Loss: 0.000356 | Val Loss: 0.000962\n",
      "Epoch 252 | Train Loss: 0.000404 | Val Loss: 0.000222\n",
      "Epoch 253 | Train Loss: 0.000343 | Val Loss: 0.000542\n",
      "Epoch 254 | Train Loss: 0.000371 | Val Loss: 0.000198\n",
      "  -> New best model saved (val_loss: 0.000198) to `agent/mlp_model.pth`\n",
      "Epoch 255 | Train Loss: 0.000334 | Val Loss: 0.000221\n",
      "Epoch 256 | Train Loss: 0.000254 | Val Loss: 0.000329\n",
      "Epoch 257 | Train Loss: 0.000427 | Val Loss: 0.000618\n",
      "Epoch 258 | Train Loss: 0.000355 | Val Loss: 0.000426\n",
      "Epoch 259 | Train Loss: 0.000286 | Val Loss: 0.000343\n",
      "Epoch 260 | Train Loss: 0.000433 | Val Loss: 0.000277\n",
      "Epoch 261 | Train Loss: 0.000268 | Val Loss: 0.000321\n",
      "Epoch 262 | Train Loss: 0.000349 | Val Loss: 0.000296\n",
      "Epoch 263 | Train Loss: 0.000319 | Val Loss: 0.000210\n",
      "Epoch 264 | Train Loss: 0.000330 | Val Loss: 0.000362\n",
      "Epoch 265 | Train Loss: 0.000327 | Val Loss: 0.000193\n",
      "  -> New best model saved (val_loss: 0.000193) to `agent/mlp_model.pth`\n",
      "Epoch 266 | Train Loss: 0.000341 | Val Loss: 0.000310\n",
      "Epoch 267 | Train Loss: 0.000288 | Val Loss: 0.000357\n",
      "Epoch 268 | Train Loss: 0.000446 | Val Loss: 0.000201\n",
      "Epoch 269 | Train Loss: 0.000265 | Val Loss: 0.000265\n",
      "Epoch 270 | Train Loss: 0.000321 | Val Loss: 0.000391\n",
      "Epoch 271 | Train Loss: 0.000290 | Val Loss: 0.000194\n",
      "Epoch 272 | Train Loss: 0.000329 | Val Loss: 0.000214\n",
      "Epoch 273 | Train Loss: 0.000290 | Val Loss: 0.000196\n",
      "Epoch 274 | Train Loss: 0.000346 | Val Loss: 0.000291\n",
      "Epoch 275 | Train Loss: 0.000351 | Val Loss: 0.000361\n",
      "Epoch 276 | Train Loss: 0.000270 | Val Loss: 0.000779\n",
      "Epoch 277 | Train Loss: 0.000352 | Val Loss: 0.000579\n",
      "Epoch 278 | Train Loss: 0.000377 | Val Loss: 0.000216\n",
      "Epoch 279 | Train Loss: 0.000334 | Val Loss: 0.005906\n",
      "Epoch 280 | Train Loss: 0.000904 | Val Loss: 0.000362\n",
      "Epoch 281 | Train Loss: 0.000399 | Val Loss: 0.000504\n",
      "Epoch 282 | Train Loss: 0.000389 | Val Loss: 0.000408\n",
      "Epoch 283 | Train Loss: 0.000315 | Val Loss: 0.000347\n",
      "Epoch 284 | Train Loss: 0.000379 | Val Loss: 0.000745\n",
      "Epoch 285 | Train Loss: 0.000316 | Val Loss: 0.000335\n",
      "Epoch 286 | Train Loss: 0.000342 | Val Loss: 0.000545\n",
      "Epoch 287 | Train Loss: 0.000371 | Val Loss: 0.000379\n",
      "Epoch 288 | Train Loss: 0.000298 | Val Loss: 0.000239\n",
      "Epoch 289 | Train Loss: 0.000298 | Val Loss: 0.000249\n",
      "Epoch 290 | Train Loss: 0.000655 | Val Loss: 0.000497\n",
      "Epoch 291 | Train Loss: 0.000302 | Val Loss: 0.000799\n",
      "Epoch 292 | Train Loss: 0.000276 | Val Loss: 0.000584\n",
      "Epoch 293 | Train Loss: 0.000320 | Val Loss: 0.000404\n",
      "Epoch 294 | Train Loss: 0.000324 | Val Loss: 0.000236\n",
      "Epoch 295 | Train Loss: 0.000307 | Val Loss: 0.000595\n",
      "Epoch 296 | Train Loss: 0.000291 | Val Loss: 0.000253\n",
      "Epoch 297 | Train Loss: 0.000381 | Val Loss: 0.000210\n",
      "Epoch 298 | Train Loss: 0.000260 | Val Loss: 0.000326\n",
      "Epoch 299 | Train Loss: 0.000446 | Val Loss: 0.000514\n",
      "Epoch 300 | Train Loss: 0.000297 | Val Loss: 0.000368\n",
      "Epoch 301 | Train Loss: 0.000307 | Val Loss: 0.000457\n",
      "Epoch 302 | Train Loss: 0.000336 | Val Loss: 0.000709\n",
      "Epoch 303 | Train Loss: 0.000411 | Val Loss: 0.000220\n",
      "Epoch 304 | Train Loss: 0.000258 | Val Loss: 0.000295\n",
      "Epoch 305 | Train Loss: 0.000278 | Val Loss: 0.000427\n",
      "Epoch 306 | Train Loss: 0.000319 | Val Loss: 0.000633\n",
      "Epoch 307 | Train Loss: 0.000292 | Val Loss: 0.000215\n",
      "Epoch 308 | Train Loss: 0.000363 | Val Loss: 0.000365\n",
      "Epoch 309 | Train Loss: 0.000259 | Val Loss: 0.000189\n",
      "  -> New best model saved (val_loss: 0.000189) to `agent/mlp_model.pth`\n",
      "Epoch 310 | Train Loss: 0.000286 | Val Loss: 0.000327\n",
      "Epoch 311 | Train Loss: 0.000263 | Val Loss: 0.000282\n",
      "Epoch 312 | Train Loss: 0.000315 | Val Loss: 0.000356\n",
      "Epoch 313 | Train Loss: 0.000453 | Val Loss: 0.000219\n",
      "Epoch 314 | Train Loss: 0.000302 | Val Loss: 0.000207\n",
      "Epoch 315 | Train Loss: 0.000323 | Val Loss: 0.000215\n",
      "Epoch 316 | Train Loss: 0.000261 | Val Loss: 0.000225\n",
      "Epoch 317 | Train Loss: 0.000277 | Val Loss: 0.000169\n",
      "  -> New best model saved (val_loss: 0.000169) to `agent/mlp_model.pth`\n",
      "Epoch 318 | Train Loss: 0.000314 | Val Loss: 0.001766\n",
      "Epoch 319 | Train Loss: 0.000395 | Val Loss: 0.000235\n",
      "Epoch 320 | Train Loss: 0.000301 | Val Loss: 0.000212\n",
      "Epoch 321 | Train Loss: 0.000300 | Val Loss: 0.000180\n",
      "Epoch 322 | Train Loss: 0.000322 | Val Loss: 0.000189\n",
      "Epoch 323 | Train Loss: 0.000248 | Val Loss: 0.000274\n",
      "Epoch 324 | Train Loss: 0.000288 | Val Loss: 0.000214\n",
      "Epoch 325 | Train Loss: 0.000246 | Val Loss: 0.000347\n",
      "Epoch 326 | Train Loss: 0.000305 | Val Loss: 0.000908\n",
      "Epoch 327 | Train Loss: 0.000275 | Val Loss: 0.000714\n",
      "Epoch 328 | Train Loss: 0.000311 | Val Loss: 0.000201\n",
      "Epoch 329 | Train Loss: 0.000273 | Val Loss: 0.000546\n",
      "Epoch 330 | Train Loss: 0.000366 | Val Loss: 0.000522\n",
      "Epoch 331 | Train Loss: 0.000294 | Val Loss: 0.000857\n",
      "Epoch 332 | Train Loss: 0.000281 | Val Loss: 0.000227\n",
      "Epoch 333 | Train Loss: 0.000277 | Val Loss: 0.000306\n",
      "Epoch 334 | Train Loss: 0.000254 | Val Loss: 0.000284\n",
      "Epoch 335 | Train Loss: 0.000402 | Val Loss: 0.000340\n",
      "Epoch 336 | Train Loss: 0.000247 | Val Loss: 0.000573\n",
      "Epoch 337 | Train Loss: 0.000276 | Val Loss: 0.000174\n",
      "Epoch 338 | Train Loss: 0.000292 | Val Loss: 0.000671\n",
      "Epoch 339 | Train Loss: 0.000351 | Val Loss: 0.000262\n",
      "Epoch 340 | Train Loss: 0.000287 | Val Loss: 0.000163\n",
      "  -> New best model saved (val_loss: 0.000163) to `agent/mlp_model.pth`\n",
      "Epoch 341 | Train Loss: 0.000226 | Val Loss: 0.000221\n",
      "Epoch 342 | Train Loss: 0.000424 | Val Loss: 0.000371\n",
      "Epoch 343 | Train Loss: 0.000226 | Val Loss: 0.000310\n",
      "Epoch 344 | Train Loss: 0.000351 | Val Loss: 0.000837\n",
      "Epoch 345 | Train Loss: 0.000283 | Val Loss: 0.000240\n",
      "Epoch 346 | Train Loss: 0.000262 | Val Loss: 0.000387\n",
      "Epoch 347 | Train Loss: 0.000245 | Val Loss: 0.000317\n",
      "Epoch 348 | Train Loss: 0.000318 | Val Loss: 0.000193\n",
      "Epoch 349 | Train Loss: 0.000247 | Val Loss: 0.000219\n",
      "Epoch 350 | Train Loss: 0.000262 | Val Loss: 0.000456\n",
      "Epoch 351 | Train Loss: 0.000267 | Val Loss: 0.000227\n",
      "Epoch 352 | Train Loss: 0.000267 | Val Loss: 0.000282\n",
      "Epoch 353 | Train Loss: 0.000284 | Val Loss: 0.000227\n",
      "Epoch 354 | Train Loss: 0.000288 | Val Loss: 0.000593\n",
      "Epoch 355 | Train Loss: 0.000290 | Val Loss: 0.000190\n",
      "Epoch 356 | Train Loss: 0.000246 | Val Loss: 0.000211\n",
      "Epoch 357 | Train Loss: 0.000281 | Val Loss: 0.000218\n",
      "Epoch 358 | Train Loss: 0.000237 | Val Loss: 0.000214\n",
      "Epoch 359 | Train Loss: 0.000250 | Val Loss: 0.000219\n",
      "Epoch 360 | Train Loss: 0.000248 | Val Loss: 0.000336\n",
      "Epoch 361 | Train Loss: 0.000366 | Val Loss: 0.000566\n",
      "Epoch 362 | Train Loss: 0.000259 | Val Loss: 0.000326\n",
      "Epoch 363 | Train Loss: 0.000289 | Val Loss: 0.000312\n",
      "Epoch 364 | Train Loss: 0.000257 | Val Loss: 0.000340\n",
      "Epoch 365 | Train Loss: 0.000292 | Val Loss: 0.000392\n",
      "Epoch 366 | Train Loss: 0.000250 | Val Loss: 0.000243\n",
      "Epoch 367 | Train Loss: 0.000328 | Val Loss: 0.000320\n",
      "Epoch 368 | Train Loss: 0.000256 | Val Loss: 0.000200\n",
      "Epoch 369 | Train Loss: 0.000226 | Val Loss: 0.000183\n",
      "Epoch 370 | Train Loss: 0.000302 | Val Loss: 0.000178\n",
      "Epoch 371 | Train Loss: 0.000363 | Val Loss: 0.001186\n",
      "Epoch 372 | Train Loss: 0.000291 | Val Loss: 0.000265\n",
      "Epoch 373 | Train Loss: 0.000238 | Val Loss: 0.000354\n",
      "Epoch 374 | Train Loss: 0.000262 | Val Loss: 0.000725\n",
      "Epoch 375 | Train Loss: 0.000266 | Val Loss: 0.000514\n",
      "Epoch 376 | Train Loss: 0.000251 | Val Loss: 0.000168\n",
      "Epoch 377 | Train Loss: 0.000372 | Val Loss: 0.000340\n",
      "Epoch 378 | Train Loss: 0.000332 | Val Loss: 0.000158\n",
      "  -> New best model saved (val_loss: 0.000158) to `agent/mlp_model.pth`\n",
      "Epoch 379 | Train Loss: 0.000210 | Val Loss: 0.000462\n",
      "Epoch 380 | Train Loss: 0.000280 | Val Loss: 0.000303\n",
      "Epoch 381 | Train Loss: 0.000243 | Val Loss: 0.000468\n",
      "Epoch 382 | Train Loss: 0.000300 | Val Loss: 0.000253\n",
      "Epoch 383 | Train Loss: 0.000276 | Val Loss: 0.000205\n",
      "Epoch 384 | Train Loss: 0.000233 | Val Loss: 0.000142\n",
      "  -> New best model saved (val_loss: 0.000142) to `agent/mlp_model.pth`\n",
      "Epoch 385 | Train Loss: 0.000386 | Val Loss: 0.000403\n",
      "Epoch 386 | Train Loss: 0.000220 | Val Loss: 0.000334\n",
      "Epoch 387 | Train Loss: 0.000252 | Val Loss: 0.000307\n",
      "Epoch 388 | Train Loss: 0.000316 | Val Loss: 0.000322\n",
      "Epoch 389 | Train Loss: 0.000223 | Val Loss: 0.000277\n",
      "Epoch 390 | Train Loss: 0.000222 | Val Loss: 0.000255\n",
      "Epoch 391 | Train Loss: 0.000225 | Val Loss: 0.000188\n",
      "Epoch 392 | Train Loss: 0.000258 | Val Loss: 0.000210\n",
      "Epoch 393 | Train Loss: 0.000311 | Val Loss: 0.000327\n",
      "Epoch 394 | Train Loss: 0.000247 | Val Loss: 0.000178\n",
      "Epoch 395 | Train Loss: 0.000231 | Val Loss: 0.000425\n",
      "Epoch 396 | Train Loss: 0.000239 | Val Loss: 0.000421\n",
      "Epoch 397 | Train Loss: 0.000298 | Val Loss: 0.000193\n",
      "Epoch 398 | Train Loss: 0.000302 | Val Loss: 0.000389\n",
      "Epoch 399 | Train Loss: 0.000275 | Val Loss: 0.000165\n",
      "Epoch 400 | Train Loss: 0.000235 | Val Loss: 0.000194\n",
      "Epoch 401 | Train Loss: 0.000280 | Val Loss: 0.000284\n",
      "Epoch 402 | Train Loss: 0.000218 | Val Loss: 0.000509\n",
      "Epoch 403 | Train Loss: 0.000282 | Val Loss: 0.000255\n",
      "Epoch 404 | Train Loss: 0.000322 | Val Loss: 0.000261\n",
      "Epoch 405 | Train Loss: 0.000230 | Val Loss: 0.000158\n",
      "Epoch 406 | Train Loss: 0.000221 | Val Loss: 0.000429\n",
      "Epoch 407 | Train Loss: 0.000244 | Val Loss: 0.000244\n",
      "Epoch 408 | Train Loss: 0.000321 | Val Loss: 0.000147\n",
      "Epoch 409 | Train Loss: 0.000278 | Val Loss: 0.000150\n",
      "Epoch 410 | Train Loss: 0.000208 | Val Loss: 0.000153\n",
      "Epoch 411 | Train Loss: 0.000298 | Val Loss: 0.000348\n",
      "Epoch 412 | Train Loss: 0.000271 | Val Loss: 0.000178\n",
      "Epoch 413 | Train Loss: 0.000287 | Val Loss: 0.000149\n",
      "Epoch 414 | Train Loss: 0.000210 | Val Loss: 0.000210\n",
      "Epoch 415 | Train Loss: 0.000253 | Val Loss: 0.000305\n",
      "Epoch 416 | Train Loss: 0.000288 | Val Loss: 0.000393\n",
      "Epoch 417 | Train Loss: 0.000259 | Val Loss: 0.000266\n",
      "Epoch 418 | Train Loss: 0.000234 | Val Loss: 0.000230\n",
      "Epoch 419 | Train Loss: 0.000235 | Val Loss: 0.000229\n",
      "Epoch 420 | Train Loss: 0.000256 | Val Loss: 0.000206\n",
      "Epoch 421 | Train Loss: 0.000302 | Val Loss: 0.000577\n",
      "Epoch 422 | Train Loss: 0.000246 | Val Loss: 0.000181\n",
      "Epoch 423 | Train Loss: 0.000215 | Val Loss: 0.000268\n",
      "Epoch 424 | Train Loss: 0.000268 | Val Loss: 0.000257\n",
      "Epoch 425 | Train Loss: 0.000241 | Val Loss: 0.000177\n",
      "Epoch 426 | Train Loss: 0.000303 | Val Loss: 0.000153\n",
      "Epoch 427 | Train Loss: 0.000275 | Val Loss: 0.000172\n",
      "Epoch 428 | Train Loss: 0.000311 | Val Loss: 0.000275\n",
      "Epoch 429 | Train Loss: 0.000254 | Val Loss: 0.000266\n",
      "Epoch 430 | Train Loss: 0.000260 | Val Loss: 0.000347\n",
      "Epoch 431 | Train Loss: 0.000285 | Val Loss: 0.000394\n",
      "Epoch 432 | Train Loss: 0.000198 | Val Loss: 0.000151\n",
      "Epoch 433 | Train Loss: 0.000229 | Val Loss: 0.000178\n",
      "Epoch 434 | Train Loss: 0.000322 | Val Loss: 0.000235\n",
      "Epoch 435 | Train Loss: 0.000223 | Val Loss: 0.000206\n",
      "Epoch 436 | Train Loss: 0.000221 | Val Loss: 0.000246\n",
      "Epoch 437 | Train Loss: 0.000298 | Val Loss: 0.000171\n",
      "Epoch 438 | Train Loss: 0.000245 | Val Loss: 0.000421\n",
      "Epoch 439 | Train Loss: 0.000213 | Val Loss: 0.000253\n",
      "Epoch 440 | Train Loss: 0.000251 | Val Loss: 0.000224\n",
      "Epoch 441 | Train Loss: 0.000233 | Val Loss: 0.000142\n",
      "Epoch 442 | Train Loss: 0.000237 | Val Loss: 0.000311\n",
      "Epoch 443 | Train Loss: 0.000209 | Val Loss: 0.000211\n",
      "Epoch 444 | Train Loss: 0.000263 | Val Loss: 0.000218\n",
      "Epoch 445 | Train Loss: 0.000255 | Val Loss: 0.000156\n",
      "Epoch 446 | Train Loss: 0.000356 | Val Loss: 0.000169\n",
      "Epoch 447 | Train Loss: 0.000194 | Val Loss: 0.000207\n",
      "Epoch 448 | Train Loss: 0.000250 | Val Loss: 0.000353\n",
      "Epoch 449 | Train Loss: 0.000222 | Val Loss: 0.000175\n",
      "Epoch 450 | Train Loss: 0.000231 | Val Loss: 0.000467\n",
      "Epoch 451 | Train Loss: 0.000207 | Val Loss: 0.000390\n",
      "Epoch 452 | Train Loss: 0.000254 | Val Loss: 0.000373\n",
      "Epoch 453 | Train Loss: 0.000211 | Val Loss: 0.000195\n",
      "Epoch 454 | Train Loss: 0.000218 | Val Loss: 0.000172\n",
      "Epoch 455 | Train Loss: 0.000237 | Val Loss: 0.000293\n",
      "Epoch 456 | Train Loss: 0.000267 | Val Loss: 0.000145\n",
      "Epoch 457 | Train Loss: 0.000214 | Val Loss: 0.000177\n",
      "Epoch 458 | Train Loss: 0.000266 | Val Loss: 0.000274\n",
      "Epoch 459 | Train Loss: 0.000211 | Val Loss: 0.000154\n",
      "Epoch 460 | Train Loss: 0.000248 | Val Loss: 0.000426\n",
      "Epoch 461 | Train Loss: 0.000321 | Val Loss: 0.000340\n",
      "Epoch 462 | Train Loss: 0.000220 | Val Loss: 0.000175\n",
      "Epoch 463 | Train Loss: 0.000221 | Val Loss: 0.000191\n",
      "Epoch 464 | Train Loss: 0.000235 | Val Loss: 0.000199\n",
      "Epoch 465 | Train Loss: 0.000217 | Val Loss: 0.000469\n",
      "Epoch 466 | Train Loss: 0.000225 | Val Loss: 0.000148\n",
      "Epoch 467 | Train Loss: 0.000240 | Val Loss: 0.000173\n",
      "Epoch 468 | Train Loss: 0.000226 | Val Loss: 0.000193\n",
      "Epoch 469 | Train Loss: 0.000229 | Val Loss: 0.000313\n",
      "Epoch 470 | Train Loss: 0.000280 | Val Loss: 0.000221\n",
      "Epoch 471 | Train Loss: 0.000238 | Val Loss: 0.000567\n",
      "Epoch 472 | Train Loss: 0.000334 | Val Loss: 0.000146\n",
      "Epoch 473 | Train Loss: 0.000195 | Val Loss: 0.000143\n",
      "Epoch 474 | Train Loss: 0.000237 | Val Loss: 0.000254\n",
      "Epoch 475 | Train Loss: 0.000214 | Val Loss: 0.000173\n",
      "Epoch 476 | Train Loss: 0.000203 | Val Loss: 0.000296\n",
      "Epoch 477 | Train Loss: 0.000204 | Val Loss: 0.000322\n",
      "Epoch 478 | Train Loss: 0.000199 | Val Loss: 0.000543\n",
      "Epoch 479 | Train Loss: 0.000264 | Val Loss: 0.000604\n",
      "Epoch 480 | Train Loss: 0.000374 | Val Loss: 0.000450\n",
      "Epoch 481 | Train Loss: 0.000178 | Val Loss: 0.000252\n",
      "Epoch 482 | Train Loss: 0.000216 | Val Loss: 0.000280\n",
      "Epoch 483 | Train Loss: 0.000261 | Val Loss: 0.000271\n",
      "Epoch 484 | Train Loss: 0.000241 | Val Loss: 0.000253\n",
      "Epoch 485 | Train Loss: 0.000214 | Val Loss: 0.000190\n",
      "Epoch 486 | Train Loss: 0.000255 | Val Loss: 0.000187\n",
      "Epoch 487 | Train Loss: 0.000241 | Val Loss: 0.000478\n",
      "Epoch 488 | Train Loss: 0.000207 | Val Loss: 0.000226\n",
      "Epoch 489 | Train Loss: 0.000238 | Val Loss: 0.000252\n",
      "Epoch 490 | Train Loss: 0.000257 | Val Loss: 0.000200\n",
      "Epoch 491 | Train Loss: 0.000220 | Val Loss: 0.000138\n",
      "  -> New best model saved (val_loss: 0.000138) to `agent/mlp_model.pth`\n",
      "Epoch 492 | Train Loss: 0.000225 | Val Loss: 0.000380\n",
      "Epoch 493 | Train Loss: 0.000244 | Val Loss: 0.000272\n",
      "Epoch 494 | Train Loss: 0.000220 | Val Loss: 0.000145\n",
      "Epoch 495 | Train Loss: 0.000212 | Val Loss: 0.000263\n",
      "Epoch 496 | Train Loss: 0.000200 | Val Loss: 0.000146\n",
      "Epoch 497 | Train Loss: 0.000216 | Val Loss: 0.000613\n",
      "Epoch 498 | Train Loss: 0.000255 | Val Loss: 0.000216\n",
      "Epoch 499 | Train Loss: 0.000296 | Val Loss: 0.000180\n",
      "Epoch 500 | Train Loss: 0.000186 | Val Loss: 0.000358\n",
      "训练结束，最优验证损失: 0.000138\n",
      "最佳模型已保存为 `agent/mlp_model.pth` （保存在 CPU 模式下的 state_dict）\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "\n",
    "# -----------------------\n",
    "# 定义三层 MLP\n",
    "# -----------------------\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int = 150,\n",
    "                 hidden_dim1: int = 256,\n",
    "                 hidden_dim2: int = 128,\n",
    "                 output_dim: int = 3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim,  hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# -----------------------\n",
    "# 训练和验证函数\n",
    "# -----------------------\n",
    "def train_one_epoch(model, optimizer, loader, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for obs, act in loader:\n",
    "        obs = obs.to(device)\n",
    "        act = act.to(device)\n",
    "\n",
    "        pred = model(obs)\n",
    "        loss = F.mse_loss(pred, act)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * obs.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for obs, act in loader:\n",
    "        obs = obs.to(device)\n",
    "        act = act.to(device)\n",
    "        pred = model(obs)\n",
    "        loss = F.mse_loss(pred, act)\n",
    "        total_loss += loss.item() * obs.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "# -----------------------\n",
    "# 主程序\n",
    "# -----------------------\n",
    "data = pd.read_csv(\"./data/data.csv\")\n",
    "\n",
    "unique_indices = data['index'].unique()\n",
    "obs_list = []\n",
    "action_list = []\n",
    "\n",
    "for idx in unique_indices:\n",
    "    traj_data = data[data['index'] == idx]\n",
    "    # 提取obs和action\n",
    "    obs_cols = ['obs_1', 'obs_2', 'obs_3', 'obs_4', 'obs_5']  # obs_0 到 obs_5\n",
    "    action_cols = ['action_1', 'action_2', 'action_3']\n",
    "    \n",
    "    obs = traj_data[obs_cols].values\n",
    "    action = traj_data[action_cols].values\n",
    "    \n",
    "    # 处理历史obs拼接\n",
    "    T = len(obs)\n",
    "\n",
    "    for t in range(T-1):\n",
    "        if t < 29:\n",
    "            # 对于前30个时间步，复制第一帧的obs\n",
    "            history = np.tile(obs[0], (30-t-1, 1))\n",
    "            current = obs[:t+1]\n",
    "            history_obs = np.concatenate([history, current]).flatten()\n",
    "        else:\n",
    "            # 对于后面的时间步，使用前30个时间步的obs\n",
    "            history_obs = obs[t-29:t+1].flatten()\n",
    "    \n",
    "        obs_list.append(history_obs)\n",
    "        action_list.append(action[t+1])\n",
    "\n",
    "obs_tensor = torch.from_numpy(np.array(obs_list)).float()\n",
    "act_tensor = torch.from_numpy(np.array(action_list)).float()\n",
    "# 构建 Dataset\n",
    "dataset = TensorDataset(obs_tensor, act_tensor)\n",
    "\n",
    "# 划分训练/验证集：90% 训练，10% 验证\n",
    "val_size   = int(len(dataset) * 0.1)\n",
    "train_size = len(dataset) - val_size\n",
    "train_ds, val_ds = random_split(\n",
    "    dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 设备和模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = Mlp().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 用来追踪效果最好的验证损失\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = \"agent/mlp_model.pth\"\n",
    "\n",
    "# 训练与验证循环\n",
    "epochs = 500\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train_one_epoch(model, optimizer, train_loader, device)\n",
    "    val_loss   = validate(model, val_loader, device)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "    # 如果当前验证集损失更好，则保存到 CPU 并序列化\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        # 将模型移动到 CPU\n",
    "        model_cpu = model.to(\"cpu\")\n",
    "        # 保存 state_dict\n",
    "        torch.save(model_cpu.state_dict(), best_model_path)\n",
    "        print(f\"  -> New best model saved (val_loss: {best_val_loss:.6f}) to `{best_model_path}`\")\n",
    "        # 再次将模型移动回训练设备\n",
    "        model = model_cpu.to(device)\n",
    "\n",
    "print(f\"训练结束，最优验证损失: {best_val_loss:.6f}\")\n",
    "print(f\"最佳模型已保存为 `{best_model_path}` （保存在 CPU 模式下的 state_dict）\")\n",
    "\n",
    "# 如果需要加载最佳模型到 CPU 并做推理，可以使用：\n",
    "# best_model = Mlp()\n",
    "# best_model.load_state_dict(torch.load(best_model_path, map_location=\"cpu\"))\n",
    "# best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "js",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
